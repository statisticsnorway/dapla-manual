# Deploy applikasjon

TL;DR:

- Applikasjoner deployes til BiP fra teamet sitt eget git repo (`flux2-tenant-<teamnavn>` eller `<teamnavn>-iac`)
- Automatisk oppdatering av images krever et par ekstra manifester for at flux skal fange opp endringene

## Introduksjon

For utrulling av applikasjoner, og manifester/filer på kubernetes bruker vi [Flux](https://fluxcd.io/flux/).
Flux er et verktøy for å synce filer i et git repositoriet med kubernetes.
Denne tilnærmingen for å ha kontroll på manifestene kalles gitops, og gjør at du som utvikler slipper å forholde deg til kubernetes-kommandoer eller andre for å få ut endringene du ønsker.

Flux tilbyr også en rekke funksjonalitet, blant annet automatisk utrulling av nye versjoner når en ny versjon av et image er tilgjengelig.

## Miljø

For BiP har vi to Kubernetesmiljøer dit applikasjoner kan bli deployet til:

- `staging-bip-app`: Staging/test
- `prod-bip-app`: Produksjon

Miljøene er i utgangspunktet så like som mulig.

## Legge til en ny applikasjon

**Forutsetninger**:

- Du er medlem av et team som er etablert på kubernetes (og dermed har tilgang til github repositoriet hvor manifestene ligger)
- Imaget for applikasjonen bygges til teamet sitt artifakt repository (eller container registry om teamet ikke er på ny teamstruktur)

Nødvendig infrastruktur provisjoneres fortrinnsvins via teamets iac-repo med terraform og atlantis.

For å legge til en ny applikasjon i clusteret (med `ssb-chart`) er planen grovt sett:

1. Opprett en fil `appnavn.yaml` i korrekt mappe (`<cluster-navn>/<evt mappe>`).
2. Filen skal inneholde følgende (kan skilles ut i tre enkeltfiler), separert med `---`. Det er mulig å ta inspirasjon av tidligere manfiester.
   a. Et manifest for `ImageRepository`, som peker på hvor imaget ligger
   b. Et manifest for `ImagePolicy` som sier hvordan automatisk oppdatering av imaget skal foregår
   c. Et manifest for `HelmRelease`, der `ssb-chart` benyttes. Dobbeltsjekk at kommentarene etter image og tag peker til korrekt `ImagePolicy` (feks `# {"$imagepolicy": "<namespace>:<navn på image policy-ressurs>:name"}`). Det er denne kommentaren som gjør at flux følger med på om ny versjon av applikasjonen skal rulles ut. Hvis man ikke ønsker autoopgradering av imaget sitt kan imagepolicy-kommentaren, `ImageRepository` og `ImagePolicy` fjernes.
3. Legg til filen i `kustomization.yaml`-filen
4. Du kan dobbeltsjekke at konfigurasjonen har blitt korrekt ved å kjøre `kustomize build .`. (krever at du har kustomize cli installert).

Etter dette er commitet og merget til main-branchen vil Flux plukke opp endringen.

Notifikasjoner blir sendt til teamet sin cd-slack-kanel (`#cd-<team-navn>`).

## Trigge flux til å hente en endring

Flux vil periodisk sjekke git repoet til teamet for endringer.
Ønsker man likevel å trigge flux til å gjøre dette umiddelbart kan det gjøres ved å kjøre kommandoen:
`flux reconcile kustomization <namespace/team-navn> -n <namespace/team-navn> --with-source`

## Se status for flux

`flux get all -n <namespace>`

## Migrering fra platform-dev

I forbindelse med oppgradering av flux fra v1 til v2 var det nødvendig å gjøre en rekke endringer.

### Plassering av manifester

Filer som tidligere lå i platform-dev ligger nå i teamet sitt eget git repo (`flux2-tenant-<teamnavn>` eller `<teamnavn>-iac` under `/apps/bip`).
Strukturen matcher det som tidligere lå i platform-dev, der man legger manifestene inn i en mappe som bestemmer hvilket cluster man går mot.

[Kustomize](https://kustomize.io/) blir benyttet for å styre hvilke filer og konfigurasjon som blir inkludert, gjennom filen `kustomization.yaml` (som kan forekomme i undermapper også). Det skal ikke være behov for å endre denne filen med tanke på at dette ble gjort under migrering.

### Generere grafana dashboard

Noen brukte tidligere et bash-skript liggende i platform-dev for å generere grafana dashboard config maps utfra json-eksporten i grafana.
Dette skriptet er fortsatt mulig å benytte ( <https://github.com/statisticsnorway/platform-dev/blob/master/bin/dashboard.sh> ), og husk at korrekt output mappe må settes.
Etter filen er generert må dashboardet inkluderes i `kustomization.yaml` i den aktuelle mappen for at filen blir plukket opp.

## Eksempel på manifest

Should not be copy pasted without considering each configuration

```yaml
# See documentation for the ImageRepository fields here: https://fluxcd.io/flux/components/image/imagerepositories/
apiVersion: image.toolkit.fluxcd.io/v1beta2
kind: ImageRepository
metadata:
  name: <app-name>
  namespace: <team-name>
spec:
  # If team is on new structure they have their own repo on artifact repository
  image: europe-north1-docker.pkg.dev/artifact-registry-5n/<team-navn>-docker/<image-name>
  interval: 10m0s
  provider: gcp
---
# See documentation for the ImagePolicy fields here: https://fluxcd.io/flux/components/image/imagepolicies/
apiVersion: image.toolkit.fluxcd.io/v1beta2
kind: ImagePolicy
metadata:
  name: <app-name>
  namespace: <team-name>
spec:
  imageRepositoryRef:
    name: <app-name>
  filterTags:
    # Flux uses naming to decide which tag is newest, hence the need to specify a pattern if semver or other versoning is not used
    # Some common patterns:
    # 1. A incrementing number (e.g. global build id)
    pattern: 'main-[a-z0-9]+-az(?P<buildid>[0-9]+)'
    extract: '$buildid'
    # 2. Timestamp of build (e.g. yyyyMMss…)
    pattern: '^main-[a-f0-9]+-(?P<ts>[0-9]+)'
    extract: '$ts'
  policy:
    # Semver is also possible. See docs
    numerical:
      order: asc
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: <app-name>
  namespace: <team-name>

# See docs ( https://github.com/statisticsnorway/helm-charts/tree/main/source/ssb-chart ) for description of each field
spec:
  interval: 10m
  chart:
    spec:
      chart: ssb-chart
      version: 4.0.1
      sourceRef:
        kind: HelmRepository
        name: ssb-helm-charts
      interval: 1h
  valuesFrom:
    - kind: ConfigMap
      name: ssb-chart-common-values
      valuesKey: values.yaml
      optional: false
  releaseName: "<app-name>"
  values:
    name: "<app-name>"
    appType: "backend"
    cluster: "<env>-bip-app"
    billingProject: "ssb-<team-navn>"
    image:
      # The comment after repository and tag maks Flux refer to the ImagePolicy defined above. Because of this comments, flux will update and commit back changes to this fields when the image updates
      repository: europe-north1-docker.pkg.dev/artifact-… # {"$imagepolicy": "<namespace>:<app-name>:name"}
      tag: 'main-…' # {"$imagepolicy": "<namespace>:<app-name>:tag"}
    port:
      name: "http"
      containerport: 8080
    replicaCount: 1
    access:
      ingress:
        internal:
          # Allow traffic from jupyterhub to this application if jwt is correct. Use keycloak as jwt issuer.
          - application: jupyterhub
            namespace: jupyterhub
            allow:
              - jwt:
                  issuer: https://keycloak.staging-bip-app.ssb.no/auth/realms/ssb
                  audiences:
                    - jupyterhub
        external:
          gateways:
            # Allow traffic from internet where jwt has audience httpbin-fe and
            - type: public
              allow:
                - jwt:
                    issuer: https://keycloak.staging-bip-app.ssb.no/auth/realms/ssb
                    audiences:
                      - httpbin-fe
                  when:
                    - key: request.headers[Authorization]
                      values: ["Bearer *"]
      egress:
        external:
          # Allow traffic out of pod to the following hosts to the given port
          - hosts:
              - "api.github.com"
              - "pubsub.googleapis.com"
              - "secretmanager.googleapis.com"
            ports:
              - name: https
                port: 443
                protocol: HTTPS
    resources:
      # Set quotas for how much cpu and memory the application requests (i.e. garuenteed resources) and limits (i.e. when the applicaiton will get killed/restarted for going over it's limit).
      enabled: true
      limits:
        memory: 4Gi
      requests:
        cpu: 200m
        memory: 512Mi
    metrics:
      enabled: true
      port: 8081
      path: /actuator/prometheus
    probes:
      # Probes are used to indicate to kubernetes when the application is ready
      # Liveness can be used to check for deadlocks (i.e. a running applications stops)
      # Readiness is used to indicate when the application is ready to receive traffic
      liveness:
        enabled: true
        livenessProbe:
          httpGet:
            port: 8081
            path: /actuator/health/liveness
      readiness:
        enabled: true
        readinessProbe:
          httpGet:
            port: 8081
            path: /actuator/health/readiness
    # serviceAccount is used to couple a google SA to this application (workload identity).
    serviceAccount:
      annotations:
        iam.gke.io/gcp-service-account: "<app-name>-wi-sa@<project-id>.iam.gserviceaccount.com"
    environmentVariables:
      - name: "FOO"
        value: "BAR"
    configs:
      - name: my-config.properties
        mountPath: /config
        config: |
          example.of.custom=config
          server.port=8080

```
