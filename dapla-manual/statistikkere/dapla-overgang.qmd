---
title: Overgang til Dapla - Steg for steg
---

Jobber du med å få over en statistikk? 
I denne artikkelen beskriver vi hvordan man bør jobbe for å få en statistikk over på Dapla, både overordnede prinsipper og en steg-for-steg veiledning.

### Steg 1: Opprette Dapla team

Det første man må gjøre når man skal få en statistikk over på Dapla er å opprette et Dapla team. Et Dapla team gir en tilgang til Google Cloud. Det er anbefalt praksis å ha ett team per seksjon. Seksjon for Prisstatistikk (s240) har eksempelvis team-navnet `prisstat`.

::: {.callout-tip}
# Hvordan oppretter du et team?
I [applikasjonen Dapla-Ctrl](https://dapla-ctrl.intern.ssb.no/)! Dette må gjøres av seksjonsleder. Les brukerveiledning i [artikkelen vår om Dapla-Ctrl](https://manual.dapla.ssb.no/statistikkere/dapla-ctrl.html#opprette-team) om du trenger hjelp.
:::

### Steg 2: Flytt data til Dapla!

En av de viktigste delene av å få en statistikk over på Dapla er å jobbe på Dapla. Derfor må man flytte noe data som man kan bruke til å bygge et produksjonsløp.

Flere i SSB bruker produksjonssonen for å skrive produksjonssløp i Python og R. Det er ikke anbefalt. Det er tre hovedgrunner til dette:

* Jobber man på bakken isolerer man seg fra ny og viktig Dapla-funksjonalitet
* Det tar tid å flytte et produksjonsløp fra bakken til sky!
* Jupyter på bakken er ikke skalert for å håndtere produksjonssløp

#### Hvordan flytter man data fra produksjonssonen til Google Cloud Storage?

##### Steg 1. Finn dataene du skal flytte

Bestem deg for hvilke data du skal begynne å jobbe med. Vi anbefaler å begynne med inndata. Kildedata kan overføres når man setter i gang med [kildomaten](kildomaten.qmd).

##### Steg 2. Klargjør dataene for flytting (filformat og filnavn)

Les filene inn i Python i jupyter i produksjonssonen og lagre de som .parquet-filer med filnavn som følger [navnestandard for datalagring](navnestandard.qmd).

##### Steg 3. Flytt dataene til ssb/cloud_sync/<dapla-team>/standard/tilsky/

Flytt så dataene til *ssb/cloud_sync/<dapla-team>/standard/tilsky/* på linux.
Hvordan dette gjøres spørs på hvor dataene ligger. Ligger dataene på linux kan man enkelt kopiere og lime ved å bruke `cp`
Ligger de på X-disken må man bruke FileZilla. Utvid boksen nedenfor for å lese hvordan man overfører data fra X-disken til linux.

:::{.callout-tip collapse=true}
# Flytte data fra X-disken til Linux

Ligger dataene du vil flytte på X-disken må du bruke FileZilla. Dette er fordi data kun kan synkroniseres mellom linux og google cloud.

For å flytte data fra X-disken følger du [denne filsluse-veiledningen skrevet av IT kundeservice](https://ssbno.sharepoint.com/sites/IT-service/SitePages/Bruk-av-filsluse.aspx?web=1).

Det eneste unntaket er at du skal skrive *sftp://sl-sas-compute-2* som vert, ikke filsluse.ssb.no

:::

##### Steg 4: Finn frem til Transfer service-området på Google Cloud Platform

1. Gå inn på [Google Cloud Console](https://console.cloud.google.com) i en nettleser.
2. Sjekk, øverst i høyre hjørne, at du er logget inn med din SSB-konto (xxx@ssb.no).
3. Velg prosjektet^[Du kan velge prosjekt øverst på siden, til høyre for teksten **Google Cloud**. I bildet under ser du at hvordan det ser ut når prosjektet `dapla-felles-p` er valgt.![](../images/gcc-project-selector.png){fig-alt="Diagram av mapper i prodsonen og bøtter på Dapla, og hvordan overføringene kan skje mellom de."}] som overføringen skal settes opp under).

* Eks. Skal vi overføre *inndata* for teamet *prisstat* vi velge prosjektet *prisstat-p*

4. Etter at du har valgt prosjekt kan du søke etter **Transfer jobs** eller **Storage transfer** i søkefeltet øverst på siden, og gå inn på siden *Transfer jobs*


##### Steg 5: Lag en transfer job for flytting fra bakke til sky

* Trykk så på `CREATE TRANSFER JOB`-knappen.
* Velg *POSIX filesystem* under source type, og *Google Cloud Storage* under Destination type
* Velg mellom *Batch* og *Event-driven* under Scheduling mode
* Velg *transfer_service_default* under Agent pool
* Velg skriv  *tilsky/* under Source directory path
* Velg bøtte du vil overføre til. Enten tilsky (*ssb-<team-navn>-data-tilsky-prod*) eller produkt (*ssb-<team-navn>-data-produkt-prod*)
* Velg overførignshyppighet. Velger du *Run once* kan du uansett kjøre tjenesten manuelt i fremtiden
* Skriv en kort beskrivelse (eks. 'Bakke til sky - engangskjøring')
* Voilà! 

##### Steg 6: Kjør transfer job!

Gå tilbake til transfer jobs-siden og kjør din nye transfer-job vewd å trykke på jobb-navnet og ~Start a run*

### Steg 7: Lag repo med SSB-project

Neste steg er å lage et repository for statistikken du skal jobbe med! Ifølge navnestandarden skal reponavnet begynne med *stat-*.

Kort fortalt gjør man det ved å kjøre `ssb-project create <repo-navn> --github --github-token='<din token>'`

Les mer i [artikkelen vår om SSB-project](ssb-project.qmd)!

::: {.callout-tip}
Nysgjerrig på hvordan et SSB-project repo ser ut? Sjekk ut [`stat-eksempel`](https://github.com/statisticsnorway/stat-eksempel) på GitHub - et fiktivt produksjonsløp utviklet av A200 støtteteam.
:::

### Steg 8: Tegn dagens produksjonssystem

### Steg 9: Jobb deg gjennom datatilstandene 

### Og så må du finne din egen vei....