---
title: Overgang til Dapla - Steg for steg
---

Jobber du med å få over en statistikk? 
I denne artikkelen beskriver vi hvordan man bør jobbe for å få en statistikk over på Dapla, både overordnede prinsipper og en steg-for-steg veiledning.

### Steg 1: Opprette Dapla team

Det første man må gjøre når man skal få en statistikk over på Dapla er å opprette et Dapla team. Et Dapla team gir en tilgang til Google Cloud. Det er anbefalt praksis å ha ett team per seksjon. Seksjon for Prisstatistikk (s240) har eksempelvis team-navnet `prisstat`.

::: {.callout-tip}
# Hvordan oppretter du et team?
I [applikasjonen Dapla-Ctrl](https://dapla-ctrl.intern.ssb.no/)! Dette må gjøres av seksjonsleder. Les brukerveiledning i [artikkelen vår om Dapla-Ctrl](https://manual.dapla.ssb.no/statistikkere/dapla-ctrl.html#opprette-team) om du trenger hjelp.
:::

### Steg 2: Flytt data til Dapla!

En av de viktigste delene av å få en statistikk over på Dapla er å jobbe på Dapla. Derfor må man flytte noe data som man kan bruke til å bygge et produksjonsløp.

Flere i SSB bruker produksjonssonen for å skrive produksjonssløp i Python og R. Det er ikke anbefalt. Det er tre hovedgrunner til dette:

* Jobber man på bakken isolerer man seg fra ny og viktig Dapla-funksjonalitet
* Det tar tid å flytte et produksjonsløp fra bakken til sky!
* Jupyter på bakken er ikke skalert for å håndtere produksjonssløp

#### Hvordan flytter man data fra produksjonssonen til Google Cloud Storage?

##### Steg 1. Finn dataene du skal flytte

Bestem deg for hvilke data du skal begynne å jobbe med. Vi anbefaler å begynne med inndata. Kildedata kan overføres når man setter i gang med [kildomaten](kildomaten.qmd).

##### Steg 2. Klargjør dataene for flytting (filformat og filnavn)

Les filene inn i Python i jupyter i produksjonssonen og lagre de som .parquet-filer med filnavn som følger [navnestandard for datalagring](navnestandard.qmd).

##### Steg 3. Flytt dataene til ssb/cloud_sync/<dapla-team>/tilsky/

Flytt så dataene til *ssb/cloud_sync/<dapla-team>/tilsky/* på linux.
Hvordan dette gjøres spørs på hvor dataene ligger. Ligger dataene på linux kan man enkelt kopiere og lime ved å bruke `cp`
Ligger de på x-disken må man bruke FileZilla. Utvid boksen nedenfor for å lese hvordan man overfører data fra x-disken til linux.

:::{.callout-tip collapse=true}
# Flytte data fra X-disken til Linux

Ligger dataene du vil flytte på x-disken må du bruke filezilla. Dette er fordi data kun kan synkroniseres mellom linux og google cloud.

For å flytte data fra x-disken følger du [denne filsluse-veiledningen skrevet av IT kundeservice](https://ssbno.sharepoint.com/sites/IT-service/SitePages/Bruk-av-filsluse.aspx?web=1).

Det eneste unntaket er at du skal skrive *sftp://sl-sas-compute-2* som vert, ikke filsluse.ssb.no

:::

##### Steg 4. Finn frem til Transfer service-området på Google Cloud Platform

1. Gå inn på [Google Cloud Console](https://console.cloud.google.com) i en nettleser.
2. Sjekk, øverst i høyre hjørne, at du er logget inn med din SSB-konto (xxx@ssb.no).
3. Velg prosjektet^[Du kan velge prosjekt øverst på siden, til høyre for teksten **Google Cloud**. I bildet under ser du at hvordan det ser ut når prosjektet `dapla-felles-p` er valgt.![](../images/gcc-project-selector.png){fig-alt="Diagram av mapper i prodsonen og bøtter på Dapla, og hvordan overføringene kan skje mellom de."}] som overføringen skal settes opp under).

* Eks. Skal vi overføre *inndata* for teamet *prisstat* vi velge prosjektet *prisstat-p*

4. Etter at du har valgt prosjekt kan du søke etter **Transfer jobs** eller **Storage transfer** i søkefeltet øverst på siden, og gå inn på siden *Transfer jobs*


##### Steg 5. Lag en transfer job for flytting fra bakke til sky



##### Steg 5. *kjøh*

### Steg 3: Lag repo med SSB-project

### Steg 4: Tegn dagens produksjonssystem

### Steg 5: Jobb deg gjennom datatilstandene 

### Og så må du finne din egen vei....