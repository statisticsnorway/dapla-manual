---
title: Hordan komme i gang med overgangen til Dapla?
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.17.0
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

Jobber du med å få over en statistikk? 
I denne artikkelen beskriver vi hvordan man bør jobbe for å få en statistikk over på Dapla, både overordnede prinsipper og en steg-for-steg veiledning.

### Steg 1: Opprette Dapla team

Det første man må gjøre når man skal få en statistikk over på Dapla er å opprette et Dapla team. Et Dapla team gir en tilgang til Google Cloud. Det er anbefalt praksis å ha ett team per seksjon. Seksjon for Prisstatistikk (s240) har eksempelvis team-navnet `prisstat`.

::: {.callout-tip}
# Hvordan oppretter du et team?
I [applikasjonen Dapla-Ctrl](https://dapla-ctrl.intern.ssb.no/)! Dette må gjøres av seksjonsleder. Les brukerveiledning i [artikkelen vår om Dapla-Ctrl](https://manual.dapla.ssb.no/statistikkere/dapla-ctrl.html#opprette-team) om du trenger hjelp.
:::

### Steg 2: Flytt data til Dapla!

En av de viktigste delene av å få en statistikk over på Dapla er å jobbe på Dapla. Derfor må man flytte noe data som man kan bruke til å bygge et produksjonsløp.

Flere i SSB bruker produksjonssonen for å skrive produksjonssløp i Python og R. Det er ikke anbefalt. Det er tre hovedgrunner til dette:

* Jobber man på bakken isolerer man seg fra ny og viktig Dapla-funksjonalitet
* Det tar tid å flytte et produksjonsløp fra bakken til sky!
* Jupyter på bakken er ikke skalert for å håndtere produksjonssløp

#### Hvordan flytter man data fra produksjonssonen til Google Cloud Storage?

##### 1. Finn dataene du skal flytte

Bestem deg for hvilke data du skal begynne å jobbe med. Vi anbefaler å begynne med inndata. Kildedata kan overføres når man setter i gang med [kildomaten](kildomaten.qmd).

##### 2. Klargjør dataene for flytting (filformat og filnavn)

Les filene inn i Python i jupyter i produksjonssonen og lagre de som .parquet-filer med filnavn som følger [navnestandard for datalagring](navnestandard.qmd).

##### 3. Flytt dataene til ssb/cloud_sync/<dapla-team>/standard/tilsky/

Flytt så dataene til *ssb/cloud_sync/<dapla-team>/standard/tilsky/* på linux.
Hvordan dette gjøres spørs på hvor dataene ligger. Ligger dataene på linux kan man enkelt kopiere og lime ved å bruke `cp`
Ligger de på X-disken må man bruke FileZilla. Utvid boksen nedenfor for å lese hvordan man overfører data fra X-disken til linux.

:::{.callout-tip collapse=true}
# Flytte data fra X-disken til Linux

Ligger dataene du vil flytte på X-disken må du bruke FileZilla. Dette er fordi data kun kan synkroniseres mellom linux og google cloud.

For å flytte data fra X-disken følger du [denne filsluse-veiledningen skrevet av IT kundeservice](https://ssbno.sharepoint.com/sites/IT-service/SitePages/Bruk-av-filsluse.aspx?web=1).

Det eneste unntaket er at du skal skrive *sftp://sl-sas-compute-2* som vert, ikke filsluse.ssb.no

:::

##### 4: Finn frem til Transfer service-området på Google Cloud Platform

1. Gå inn på [Google Cloud Console](https://console.cloud.google.com) i en nettleser.
2. Sjekk, øverst i høyre hjørne, at du er logget inn med din SSB-konto (xxx@ssb.no).
3. Velg prosjektet^[Du kan velge prosjekt øverst på siden, til høyre for teksten **Google Cloud**. I bildet under ser du at hvordan det ser ut når prosjektet `dapla-felles-p` er valgt.![](../images/gcc-project-selector.png){fig-alt="Diagram av mapper i prodsonen og bøtter på Dapla, og hvordan overføringene kan skje mellom de."}] som overføringen skal settes opp under).

* Eks. Skal vi overføre *inndata* for teamet *prisstat* vi velge prosjektet *prisstat-p*

4. Etter at du har valgt prosjekt kan du søke etter **Transfer jobs** eller **Storage transfer** i søkefeltet øverst på siden, og gå inn på siden *Transfer jobs*


##### 5: Lag en transfer job for flytting fra bakke til sky

* Trykk så på `CREATE TRANSFER JOB`-knappen.
* Velg *POSIX filesystem* under source type, og *Google Cloud Storage* under Destination type
* Velg mellom *Batch* og *Event-driven* under Scheduling mode
* Velg *transfer_service_default* under Agent pool
* Velg skriv  *tilsky/* under Source directory path
* Velg bøtte du vil overføre til. Enten tilsky (*ssb-<team-navn>-data-tilsky-prod*) eller produkt (*ssb-<team-navn>-data-produkt-prod*)
* Velg overførignshyppighet. Velger du *Run once* kan du uansett kjøre tjenesten manuelt i fremtiden
* Skriv en kort beskrivelse (eks. 'Bakke til sky - engangskjøring')
* Voilà! 

##### 6: Kjør transfer job!

Gå tilbake til transfer jobs-siden og kjør din nye transfer-job vewd å trykke på jobb-navnet og ~Start a run*

### Steg 3: Lag repo med SSB-project

Neste steg er å lage et repository for statistikken du skal jobbe med! Ifølge navnestandarden skal reponavnet begynne med *stat-*.

Kort fortalt gjør man det ved å kjøre `ssb-project create <repo-navn> --github --github-token='<din token>'`

Les mer i [artikkelen vår om SSB-project](ssb-project.qmd)!

::: {.callout-tip}
Nysgjerrig på hvordan et SSB-project repo ser ut? Sjekk ut [`stat-eksempel`](https://github.com/statisticsnorway/stat-eksempel) på GitHub - et fiktivt produksjonsløp utviklet av A200 støtteteam.
:::

### Steg 4: Tegn dagens produksjonssystem

Skal vi lage bedre produksjonssystemer på Dapla må vi kunne analysere dagens systemer for å unngå å kopiere systemene vi har i dag.

Derfor er det lurt å lage en oversikt over hvordan data flyter gjennom ulike systemer i dagens produksjonsopplegg. Dette kan gjelde alle stegene fra datainnsamling og klargjøring til analyse og publisering. 
 
For å forenkle denne prosessen og ha en felles forståelse av både nåværende («as-is») og framtidige («to-be») produksjonsløp, er det laget et helhetlig opplegg som kombinerer et Excel-skjema med automatisk generering av visualiseringer i Tableau.
 
Kort fortalt innebærer dette at statistikkprodusenter selv fyller inn informasjon om hvilke systemer og datasett som er i bruk, hvordan dataene transformeres underveis, og i hvilken rekkefølge de ulike stegene finner sted. Thomas Bjørnskau kan bistå med dette og konverterer skjemaet til dataflytdiagrammer ved hjelp av Tableau.

### Steg 5: Jobb deg gjennom datatilstandene 

Når alt annet er på plass kan man begynne å lage det nye produksjonssystemet - en datatilstand om gangen. Det er slik vi har gjort det i [stat-eksempel](https://github.com/statisticsnorway/stat-eksempel).

### Og så må du finne din egen vei.... Men her har du noen tips!! 

#### 1. Ta finpussen til slutt!

* Ref. [First Rule Of Optimization](https://wiki.c2.com/?FirstRuleOfOptimization)
* Ikke heng deg opp i finpuss som detaljert dokumentasjon, visualiseringer og nice-to-haves
    -> God dokumentasjon er viktig, men vi anbefaler å ta detaljene til slutt

#### 2. Bruk [ssb-fagfunksjoner](https://github.com/statisticsnorway/ssb-fagfunksjoner) - en python-pakke med masse fellesfunksjonalitet

* ... som for eksempel funksjoner for versjonering vist frem i [navnestandard-artikkelen vår](navnestandard.qmd).

#### 3. Spør om hjelp!

* Bruk støtteteamene, statistikktjenester, viva engage og andre kanaler