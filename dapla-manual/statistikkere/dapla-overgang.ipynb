{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Hordan komme i gang med overgangen til Dapla?\n",
        "---"
      ],
      "id": "e1ee03e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I denne artikkelen beskriver vi hva man bør gjøre og hvordan man bør jobbe for å få en statistikk over på Dapla. Rekkefølgen punktene er i er ikke tilfeldig men med unntak av første punkt - planlegging - kan rekkefølgen på hvordan man gjør ting variere.\n",
        "\n",
        "### Planlegg overgangen og tegn dagens produksjonssystem\n",
        "\n",
        "Når man skal legge en statistikk over på Dapla bør man planlegge godt. En del av dette er å se på dagens systemer for å identifisere forbedringspunkter. Derfor anbefales det at man lager en oversikt over dagens produksjonssystem. \n",
        " \n",
        "For å forenkle denne prosessen og ha en felles forståelse av både nåværende («as-is») og framtidige («to-be») produksjonsløp, er det laget et helhetlig opplegg som kombinerer et Excel-skjema med automatisk generering av visualiseringer i Tableau.\n",
        " \n",
        "Kort fortalt innebærer dette at statistikkprodusenter selv fyller inn informasjon om hvilke systemer og datasett som er i bruk, hvordan dataene transformeres underveis, og i hvilken rekkefølge de ulike stegene finner sted. Thomas Bjørnskau kan bistå med dette og konverterer skjemaet til dataflytdiagrammer ved hjelp av Tableau.\n",
        "\n",
        "I tillegg kan man få veiledning fra Seksjon for Operasjonell forretningsstøtte (s821), støtteteamene og Tech Coachene. Det anbefales det sterkeste å ta kontakt med de nevnte instansene i det man setter i gang med omleggingen av produksjonssystem(ene).\n",
        "\n",
        "Veien blir til mens man går så det forventes ikke at man har en helhetlig plan for produksjonssløpene før man setter i gang med det konkrete.\n",
        "\n",
        "### Opprette Dapla team\n",
        "\n",
        "Å bestemme teamstruktur er en naturlig fortsettelse av planleggingen. Her er det først og fremst sikkerhetshensyn som legger føring for hvor mange Dapla team man skal ha per seksjon da Dapla-team er knyttet til tilgansstyring. Et Dapla team skal bestå av medarbeidere som jobber med de samme dataene og statistikkproduktene. Vi anbefaler å ta kontakt med støtteapparatene som ble nevnt i forrige punkt her og.\n",
        "\n",
        "::: {.callout-tip}\n",
        "# Hvordan oppretter du et team?\n",
        "I [applikasjonen Dapla-Ctrl](https://dapla-ctrl.intern.ssb.no/). Dette må gjøres av seksjonsleder. Les brukerveiledning i [artikkelen vår om Dapla-Ctrl](https://manual.dapla.ssb.no/statistikkere/dapla-ctrl.html#opprette-team) om du trenger hjelp med det tekniske, men husk å ta den endelige avgjørelsen i samarbeid med støtteapparatene.\n",
        ":::\n",
        "\n",
        "### Flytt data til Dapla!\n",
        "\n",
        "En av de viktigste delene av å få en statistikk over på Dapla er å faktisk jobbe på Dapla. Derfor bør man flytte noe data som man kan bruke til å bygge deler av produksjonsløpet. Her kan man enten lage testdata eller bruke fjorårets data. Det anbefales å begynne med inndata da man mest sannsynlig ikke har datafangst på plass når man begynner å legge om et løp.\n",
        "\n",
        "Når man flytter data bør man begynne å skape seg en oversikt over hvilke data som finnes på bakken og hvordan disse dataene er organisert. Det vil for mange ta lang tid å få oversikt over eksisterende data og hva/hvordan man skal arkivere men det er lurt å begynne å tenke på dette fra første stund.\n",
        "\n",
        "I tillegg er det viktig at man begynner å tenke på hvordan man skal organisere dataene på Dapla i henhold til [navnestandard for datalagring](https://manual.dapla.ssb.no/statistikkere/navnestandard.html#mappestruktur).\n",
        "\n",
        "Flere i SSB bruker produksjonssonen for å skrive produksjonssløp i Python og R. Det er ikke anbefalt med mindre man har avhengigheter på bakken. Selv om man har avhengigheter på bakken er den generelle anbefalingen at man lager test-data eller flytter inndata fra bakke til sky og utvikler produksjonsløpet fra inndata og ut. Her er noen av grunnene til at vi fraråder å utvikle løpene på bakken:\n",
        "\n",
        "* Jobber man på bakken isolerer man seg fra ny og viktig Dapla-funksjonalitet.\n",
        "* Det tar tid å flytte et produksjonsløp fra bakken til sky!\n",
        "* Jupyter på bakken er ikke skalert for å håndtere produksjonssløp.\n",
        "\n",
        "Produksjonssonen er likevel et bra sted for å gjøre seg kjent med python og R men så fort man skal faktisk bygge et løp anbefaler vi å gjøre det i skyen.\n",
        "\n",
        ":::{.callout-note collapse=true}\n",
        "#### Hvordan flytter man data fra produksjonssonen til Google Cloud Storage?\n",
        "\n",
        "##### 1. Finn dataene du skal flytte\n",
        "\n",
        "Bestem deg for hvilke data du skal begynne å jobbe med. Vi anbefaler å begynne med inndata. Kildedata kan overføres når man setter i gang med [kildomaten](kildomaten.qmd).\n",
        "\n",
        "##### 2. Klargjør dataene for flytting (filformat og filnavn)\n",
        "\n",
        "Les filene inn i Python i jupyter i produksjonssonen og lagre de som .parquet-filer med filnavn som følger [navnestandard for datalagring](navnestandard.qmd).\n",
        "\n",
        "##### 3. Flytt dataene til ssb/cloud_sync/<dapla-team>/standard/tilsky/\n",
        "\n",
        "Flytt så dataene til *ssb/cloud_sync/<dapla-team>/standard/tilsky/* på linux.\n",
        "Hvordan dette gjøres spørs på hvor dataene ligger. Ligger dataene på linux kan man enkelt kopiere og lime ved å bruke `cp`\n",
        "Ligger de på X-disken må man bruke FileZilla. Utvid boksen nedenfor for å lese hvordan man overfører data fra X-disken til linux.\n",
        "\n",
        ":::{.callout-tip collapse=true}\n",
        "# Flytte data fra X-disken til Linux\n",
        "\n",
        "Ligger dataene du vil flytte på X-disken må du bruke FileZilla. Dette er fordi data kun kan synkroniseres mellom linux og google cloud.\n",
        "\n",
        "For å flytte data fra X-disken følger du [denne filsluse-veiledningen skrevet av IT kundeservice](https://ssbno.sharepoint.com/sites/IT-service/SitePages/Bruk-av-filsluse.aspx?web=1).\n",
        "\n",
        "Det eneste unntaket er at du skal skrive *sftp://sl-sas-compute-2* som vert, ikke filsluse.ssb.no\n",
        "\n",
        ":::\n",
        "\n",
        ":::{.callout-tip collapse=true}\n",
        "# Kopiere .xlsx-filer fra admsonen til bøtte\n",
        "- Dra excel-filen inn i filstrukturen i Jupyterlab\n",
        "- Kjør følgende kode fra .py-fil i samme område:\n"
      ],
      "id": "50ee6ce1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        " import shutil\n",
        " import os\n",
        "\n",
        " kilde_fil = 'min_fil_lastet_inn_i_jupyerlab.xlsx'\n",
        " dest_fil = '/buckets/tilsky/test/min_fil_lastet_inn_i_jupyerlab.xlsx'\n",
        "\n",
        " folder = os.path.dirname(dest_fil)\n",
        " os.makedirs(folder, exist_ok=True)\n",
        "\n",
        " shutil.copy(kilde_fil, dest_fil)"
      ],
      "id": "c3b50e12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- slett excel-filen i Jupyterlab\n",
        ":::\n",
        "\n",
        "##### 4: Finn frem til Transfer service-området på Google Cloud Platform\n",
        "\n",
        "1. Gå inn på [Google Cloud Console](https://console.cloud.google.com) i en nettleser.\n",
        "2. Sjekk, øverst i høyre hjørne, at du er logget inn med din SSB-konto (xxx@ssb.no).\n",
        "3. Velg prosjektet^[Du kan velge prosjekt øverst på siden, til høyre for teksten **Google Cloud**. I bildet under ser du at hvordan det ser ut når prosjektet `dapla-felles-p` er valgt.![](../images/gcc-project-selector.png){fig-alt=\"Diagram av mapper i prodsonen og bøtter på Dapla, og hvordan overføringene kan skje mellom de.\"}] som overføringen skal settes opp under.\n",
        "\n",
        "* Eks. Skal vi overføre *inndata* for teamet *prisstat* vi velge prosjektet *prisstat-p*\n",
        "\n",
        "4. Etter at du har valgt prosjekt kan du søke etter **Transfer jobs** eller **Storage transfer** i søkefeltet øverst på siden, og gå inn på siden *Transfer jobs*\n",
        "\n",
        "\n",
        "##### 5: Lag en transfer job for flytting fra bakke til sky\n",
        "\n",
        "* Trykk så på `CREATE TRANSFER JOB`-knappen.\n",
        "* Velg *POSIX filesystem* under source type, og *Google Cloud Storage* under Destination type\n",
        "* Velg mellom *Batch* og *Event-driven* under Scheduling mode\n",
        "* Velg *transfer_service_default* under Agent pool\n",
        "* Velg skriv  *tilsky/* under Source directory path\n",
        "* Velg bøtte du vil overføre til. Enten tilsky (*ssb-<team-navn>-data-tilsky-prod*) eller produkt (*ssb-<team-navn>-data-produkt-prod*)\n",
        "* Velg overførignshyppighet. Velger du *Run once* kan du uansett kjøre tjenesten manuelt i fremtiden\n",
        "* Skriv en kort beskrivelse (eks. 'Bakke til sky - engangskjøring')\n",
        "* Voilà! \n",
        "\n",
        "##### 6: Kjør transfer job!\n",
        "\n",
        "Gå tilbake til transfer jobs-siden og kjør din nye transfer-job ved å trykke på jobb-navnet og *Start a run*\n",
        ":::\n",
        "\n",
        "### Lag repo med SSB-project\n",
        "\n",
        "Man bør også lage et repository for statistikken man skal jobbe med tidlig i prosessen. Ifølge [navnestandarden](https://manual.dapla.ssb.no/statistikkere/navnestandard.html#mappestruktur) skal reponavnet begynne med *stat-*.\n",
        "\n",
        "Kort fortalt gjør man det ved å kjøre `ssb-project create <repo-navn> --github --github-token='<din token>'`. Dette forutsetter at man har konfigurert GitHub-bruker. Les om hvordan man gjør det i [vår artikkel om Git og Github]().\n",
        "\n",
        "Les mer i [artikkelen vår om SSB-project](ssb-project.qmd)!\n",
        "\n",
        "::: {.callout-tip}\n",
        "Nysgjerrig på hvordan et SSB-project repo ser ut? Sjekk ut [`stat-eksempel`](https://github.com/statisticsnorway/stat-eksempel) på GitHub - et fiktivt produksjonsløp utviklet av A200 støtteteam.\n",
        ":::\n",
        "\n",
        "### Jobb deg gjennom datatilstandene \n",
        "\n",
        "Når alt annet er på plass kan man begynne å lage det nye produksjonssystemet - en datatilstand om gangen. Det er slik vi har gjort det i [stat-eksempel](https://github.com/statisticsnorway/stat-eksempel). Vi har et kapittel om standarder med flere nyttige artikler, deriblant [artikkelen  om datatilstander]()\n",
        "\n",
        "### Og så må du finne din egen vei.... Men her har du noen tips! (og ting å tenke på)\n",
        "\n",
        "#### Ta finpussen til slutt!\n",
        "\n",
        "* Ref. [First Rule Of Optimization](https://wiki.c2.com/?FirstRuleOfOptimization)\n",
        "* Ikke heng deg opp i finpuss som detaljert dokumentasjon, visualiseringer og nice-to-haves\n",
        "    -> God dokumentasjon underveis er viktig, men vi anbefaler å ta detaljene til slutt\n",
        "\n",
        "#### Bruk [ssb-fagfunksjoner](https://github.com/statisticsnorway/ssb-fagfunksjoner) - en python-pakke med masse fellesfunksjonalitet\n",
        "\n",
        "* ... som for eksempel funksjoner for versjonering vist frem i [navnestandard-artikkelen vår](navnestandard.qmd).\n",
        "\n",
        "#### Gjør det godt kjent med krav og standarder\n",
        "\n",
        "* Investerer man tid i å standardene og kravene til statistikkproduksjon på Dapla i starten av en overgang vil man unngå hodebry i fremtiden og spare mye tid. Les artiklene våre om  [standarder](https://manual.dapla.ssb.no/statistikkere/standarder.html).\n",
        "\n",
        "#### Be om hjelp!\n",
        "\n",
        "* Bruk støtteteamene, statistikktjenester, viva engage og andre kanaler"
      ],
      "id": "8bd91ad3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}