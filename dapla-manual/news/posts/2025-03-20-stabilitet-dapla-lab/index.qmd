---
title: Arbeid rundt stabilitet i Dapla Lab
subtitle:  <todo>
categories:
  - Dapla Lab
author:
  - name: John Kasper Svergja
    affiliation: 
      - name: Seksjon for dataplattform (724)
        email: hnk@ssb.no
date: "03/20/2025"
date-modified: "03/20/2025"
image: ../../../images/dapla-long.png
image-alt: "Bilde av Dapla-logoen"
lightbox: true
draft: false
---

TL;DR:
- Vi forventer færre avbrudd i tjenester relatert til skalering av maskiner.
- Vi forventer økt stabilitet i tjenester relatert til konkurerende minnebruk på maskiner.

Med overgang fra "gamle" Jupyter til Dapla Lab og flere valg og fleksibilitet med tanke på tjenester og konfigurasjon møter vi på nye utfordringer knyttet til opplevd stabilitet fra brukeren.

Som bruker av Dapla Lab ønsker man forutsigbarhet og et stabilt miljø man kan stole på når man sitter og jobber. Spørsmålet som da stiller seg er hvordan plattformteamene kan ettergå samt levere dette etter beste evne, med de forutsetningene og den underliggende plattformen som er satt.
"Under the hood" benyttes Kubernetes, som på sett og vis har blitt bransjestandarden for plattformer. Det har sitt utspring i Google, og brukes i utstrakt grad i industrien i dag. Både Nais og gamle BIP bygger på denne platformen - og nå også Dapla Lab.

Når en tjeneste startes i Dapla Lab bestemmer Kubernetes hvilken underliggende maskin (også kalt node) tjenesten skal starte på. Hvis det er for lite kapasitet vil Kubernetes starte en ny maskin. Denne skaleringen er grunnen til at oppstart av en tjeneste noen ganger kan ta ekstra tid. 
Skulle det vise seg at vi har flere maskiner enn nødvendig vil de overflødige maskinene bli skrudd av. Ved å kun kjøre det minste nødvendige antallet med maskiner får vi en mer kostnadseffektiv drift. En konsekvens av dette har vært at tjenester plutselig kan oppleve et midlertidig avbrudd mens tjenesten blir flyttet fra en maskin til en annen. 
Etter tilbakemelding fra brukerne har vi endret denne praksisen, og lar nå tjenestene kjøre videre på samme maskin, selv om det er ledig kapasitet på andre maskiner. **Vi oppfordrer deg til å stanse tjenesten når du ikke lengre har behov for den.**

< illustrasjon som viser scale up og ned >

Når du som bruker i Dapla Lab konfigurerer tjenesten din med CPU og minne blir det satt føringer som må overholdes av Kubernetes. Den ene føringen er en forespørsel - mengden CPU/minne man er garantert å få - og den andre er grensen/taket.
Hvis man går over taket vil Kubernetes drepe tjenesten og starte den på nytt.
I "tradisjonelle" applikasjoner (tenk f.eks. Klass sitt API) gir forespørsler og grenser mening, grunnet naturlig variasjon i belastning og trafikk, og at applikasjonene er designet for å kunne feile, starte på nytt ofte og kjøre flere i parallel. Hvis den om og om igjen går over grensen sin tyder dette på en feil i applikasjonen (f.eks. minnelekkasje).
Kubernetes benytter seg av det forespurte minnet når den velger hvilken maskin tjenesten eller applikasjonen skal kjøre på. Det vil si at det er mulig å totalt ha en høyere minnegrense enn hva som er tilgjengelig på noden. Et eksempel på dette er hvis tjeneste A har minneforespørsel/-grense på 100GB/150GB, og tjeneste B har tilsvarende, men maskinen bare har 256GB med minne tilgjengelig. Da er vi i et scenario der maskinen ikke har nok minne hvis både tjeneste A og tjeneste B bruker opp til minnegrensen sin. I dette tilfellet vil en tjeneste på maskinen bli drept og startet på nytt. Merk at dette kan være en tilfeldig tjeneste på maskinen, ikke nødvendigvis den som bruker mest minne.
Vi har sett at det for tjenester på Dapla Lab ikke gir mening å differensiere på forespørsel og grense, som i tradisjonelle applikasjoner. Derfor er det nå innført en endring der forespørselen er lik grensen.
Dette håper vi gjør det mer forutsigbart for brukeren hva de kan forvente av tilgjengelig minne, samtidig som stabiliteten for alle brukerne ved at "minnetunge" brukere ikke påvirker andre sine tjenester.

Det å velge korrekte maskiner er ikke nødvendigvis en enkel oppgave, da generell bruk av maskinen må veies opp mot kost. Kostnadsdriveren for maskinene Dapla Lab og tjenestene kjører på er minne. Den nysgjerrige kan ta en titt på pris-oversikten her: https://cloud.google.com/compute/all-pricing?hl=nb. Vi kjører maskintype `n2` (standard og highmem).
Ved å monitorere og observere bruken av ressurser gjør vi nå også endringer i hvilke underliggende maskiner som kan kjøres opp. Fremover vil vi kjøre opp færre store maskiner enn flere små (fordi det finnes en basiskostnad for hver ekstra maskin), samtidig som vi nå innfører en maskintype som ikke har like mye minne som andre (`n2-standard-80`). Det vil være kostnadseffektivt for dem som trenger mye CPU men ikke nødvendigvis masse minne.
Dette vil være noe brukerne ikke merker eller vil ha et forhold til.


< foto - bruksmønster av cpu og pod i clusteret>
En generell oppfordring til våre brukere er å ikke etterspørre mer ressurser enn det man tror man trenger.





