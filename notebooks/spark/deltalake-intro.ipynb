{
 "cells": [
  {
   "cell_type": "raw",
   "id": "84bacee7-211b-4b0a-b6eb-5ab3da52cf16",
   "metadata": {},
   "source": [
    "---\n",
    "freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3421b-ac03-453e-8c98-d05c1ba97922",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduksjon til Delta Lake\n",
    "\n",
    "Delta Lake er et databaselag som kan *legges over* parquet-filer i bøtter. Det kan gi oss mye av den funksjonaliteten vi har vært vant til i relasjonelle databaser og datavarehus. I denne notebooken vises hvordan man kan ta det i bruk på Dapla. \n",
    "\n",
    "## Oppsett\n",
    "\n",
    "Hvis du logger deg inn på <https://jupyter.dapla.ssb.no/> kan du ta i bruk Delta Lake via Spark. Men for å gjøre det må du installere [delta-spark](https://pypi.org/project/delta-spark/). For å installere pakken må du jobbe i et [ssb-project](https://manual.dapla.ssb.no/jobbe-med-kode.html#ssb-project). I tillegg må du installere `delta-spark`-versjon som er kompatibel med Spark-versjonen som er installert på Dapla. Gjør derfor følgende:\n",
    "\n",
    "1. [Opprett et ssb-project](https://manual.dapla.ssb.no/jobbe-med-kode.html#ssb-project) med kommandoen:  \n",
    "`ssb-project create test-delta-lake`\n",
    "2. I terminalen skriver du følgende for å sjekke Spark-versjonen som er installert:  \n",
    "`spark-shell --version`\n",
    "3. [Sjekk hvilken **delta-spark**-versjon](https://docs.delta.io/latest/releases.html) som er kompatibel med din Spark-versjon og installer den med kommandoen^[I eksempelet er det Spark V3.3.1 som er installert og jeg installerer derfor delta-spark v2.3]:   \n",
    "`poetry add delta-spark@2.3`\n",
    "4. Åpne en ny notebook og velg kernel `test-delta-lake`. \n",
    "\n",
    "Nå har du satt opp et virtuelt miljø med en PySpark-kernel som kjører en maskin (såkalt Pyspark local kernel), der du har installert delta-spark. Vi kan nå importere de bibliotekene vi trenger og sette igang en Spark-session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398549f-f7cf-4298-8254-ece4a08fa5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importerer biblioteker\n",
    "import pyspark\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ed22e-d8d0-4777-9c8a-fdefd654f98b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Deretter initialiserer jeg en Spark-session. `%%capture_output` er med for å forhindre at det ikke blir printet ut sensitiv informasjon i en notebook som skal inn i Dapla-manualen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037f70d-e6f8-4fd3-8a18-8b358ca9613f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "%run /usr/local/share/jupyter/kernels/pyspark_local/init.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5bdfb3-618c-4147-817a-756516975571",
   "metadata": {},
   "source": [
    "## Genererer noe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5dd7d8-b1de-477b-8521-637698cc0f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Genererer noe data med Spark\n",
    "data = spark.range(10, 15)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdeb07a-5593-430f-819d-9e80501946d9",
   "metadata": {},
   "source": [
    "## Skriver ut en Delta Lake Table\n",
    "\n",
    "La oss skrive ut Spark DataFrame som en Delta Lake Table og bli kjent med strukturen i objektet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9dc42-599f-414b-ab95-c7a6e94780c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data.write.format(\"delta\").mode(\"overwrite\").save(\n",
    "    \"gs://ssb-dapla-felles-data-delt-prod/temp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9fa65-6b14-43ad-a488-18c0028f9d3d",
   "metadata": {},
   "source": [
    "Vi kan deretter printe ut hva som ble opprettet når vi skrev ut en Delta Lake Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a2616-f5cb-4648-ae6a-f11b6d0e6093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dapla import FileClient\n",
    "\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "\n",
    "fs.glob(\"gs://ssb-dapla-felles-data-delt-prod/temp4/**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8240cc2f-8747-4390-b991-f61fa72fdfd6",
   "metadata": {},
   "source": [
    "### Delta Lake Tabellstruktur\n",
    "\n",
    "Mappenstrukturen du ser over er typisk for en Delta Lake-tabell. La oss bryte ned komponentene:\n",
    "\n",
    "1. **`_delta_log/`**:\n",
    "   - Dette er transaksjonsloggmappen for Delta Lake-tabellen. Den inneholder en serie med JSON-filer som registrerer alle transaksjoner gjort på tabellen.\n",
    "   - Transaksjonsloggen er avgjørende for Delta Lakes ACID-transaksjonsegenskaper, som muliggjør funksjoner som atomiske forpliktelser, tilbakerullinger og tid-reise-forespørsler.\n",
    "\n",
    "2. **`_delta_log/00000000000000000000.json`**:\n",
    "   - Dette er en JSON-fil innenfor transaksjonsloggkatalogen. Hver JSON-fil i denne mappen tilsvarer en transaksjon (eller en batch av transaksjoner) gjort på tabellen.\n",
    "   - Filnavnet er null-fylt og representerer transaksjonsversjonen. I dette tilfellet representerer `00000000000000000000.json` den aller første versjonen (versjon 0) av tabellen. Etter hvert som flere transaksjoner blir gjort, vil nye filer bli lagt til med økende versjonsnumre.\n",
    "\n",
    "3. **`part-00000-450715bd-6b0c-4827-bb8a-b0265505ca72-c000.snappy.parquet`** og **`part-00001-977ed55f-5ce5-469f-8a1d-9eafb143c215-c000.snappy.parquet`**:\n",
    "   - Dette er de faktiske datafilene til Delta Lake-tabellen, lagret i Parquet-format.\n",
    "   - `.snappy.parquet`-utvidelsen indikerer at dataene er komprimert ved hjelp av Snappy-komprimeringsalgoritmen.\n",
    "   - Filnavnene er typiske for Sparks navngivningskonvensjon for datadeler. Prefiksene `part-00000` og `part-00001` indikerer partisjonsnumre. De lange UUID-lignende strengene er unike identifikatorer for datafilene. Suffikset `c000` indikerer Spark-oppgaven som skrev filen.\n",
    "\n",
    "Mappen representerer en Delta Lake-tabell med data lagret i Parquet-format og en transaksjonslogg som sporer endringer i tabellen. Tilstedeværelsen av `_delta_log`-mappen og innholdet er det som skiller en Delta Lake-tabell fra et vanlig Parquet-datasett.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5345de5-f48e-450c-8c16-d7f765566424",
   "metadata": {},
   "source": [
    "## Lese inn tabell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78bc00-1ef9-49d9-b8a0-87b3a7ec74ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"gs://ssb-dapla-felles-data-delt-prod/temp4\")\n",
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df1c88-6648-486f-95f7-89b20cba2de0",
   "metadata": {},
   "source": [
    "## Modifisere datasettet\n",
    "\n",
    "La oss modifisere datasettet ved å bytte ut verdien `13` med `15` i `id`-kolonnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42699f66-ed3a-4fbb-ab54-a5f6874b0a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# Update the cell with value 13 to 15\n",
    "deltaTable.update(condition=(col(\"id\") == 13), set={\"id\": lit(15)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69de71a-39b5-423a-9219-f68acd326320",
   "metadata": {},
   "source": [
    "Et viktig poeng å få med seg her er at vi nå oppdaterte Delta Lake Table objektet både i minnet og på disk. La oss bevise det ved å lese inn fra disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10a295-843b-41e8-b407-f8fe1daf275b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable2 = DeltaTable.forPath(spark, \"gs://ssb-dapla-felles-data-delt-prod/temp4\")\n",
    "deltaTable2.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9c5d1-afa8-4fd9-9c83-43c3ccaf6d2d",
   "metadata": {},
   "source": [
    "Og deretter ved å printe ut det opprinnelige objektet vi leste inn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258ccf3-6701-496c-baea-1bbff4274e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38884c83-5ffa-4f79-b428-8b4e6fe6f46e",
   "metadata": {},
   "source": [
    "## Append data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389af127-b5ce-4c79-a389-8732287c08a8",
   "metadata": {},
   "source": [
    "La oss legge til verdiene `20` og `21` til datasettet. Først lager vi en Spark dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64e127-54ed-4a2b-8d35-a052faf985d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data = [(20,), (21,)]\n",
    "new_df = spark.createDataFrame(new_data, [\"id\"])\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a1905-0529-4f37-9f99-41b914130b32",
   "metadata": {},
   "source": [
    "Deretter kan vi appendere det til vår opprinnelige dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6b418-3cb7-4360-bbd0-e09d7f82faf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.write.format(\"delta\").mode(\"append\").save(\n",
    "    \"gs://ssb-dapla-felles-data-delt-prod/temp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1182c79-36a5-4d4d-beb0-a72b3d377caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltaTable.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606705e-5efb-4ae3-be09-1ac693d3740e",
   "metadata": {},
   "source": [
    "## Historien og metadata til filen\n",
    "\n",
    "Nå som vi har gjort noen endringer kan vi se på historien til filen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805cfdb-9081-4d6a-8840-48898aaa3956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lister ut filene i bøtta\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "fs.glob(\"gs://ssb-dapla-felles-data-delt-prod/temp4/**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacbeb6f-e80c-4d7a-9c81-405887983e12",
   "metadata": {},
   "source": [
    "Vi ser av transaksjonsloggen i `_delta_log`-mappen at det nå har vært 3 transaksjoner på datasettet. vi ser også av navnene på parquet-filene, `part-00000` og `part-00001`, at det finnes to versjoner av filen. Hvis vi ønsker å bli bedre kjent med hva slags informasjon som blir lagret fra transaksjonene, så kan vi printe ut den siste transaksjonen som heter `00000000000000000002.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e687c-b0f3-4c5b-9327-6619196e5348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from dapla import FileClient\n",
    "\n",
    "# Kobler oss på bøttene\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "\n",
    "# Filsti\n",
    "path = \"gs://ssb-dapla-felles-data-delt-prod/temp4/_delta_log/00000000000000000002.json\"\n",
    "\n",
    "with fs.open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        pretty_content = json.dumps(data, indent=4)\n",
    "        print(pretty_content)\n",
    "        print(\"-\" * 50)  # Print separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c37fde-12e8-4485-bd0d-1098681f75fc",
   "metadata": {},
   "source": [
    "Her ser vi at vi får masse informasjon om endringen, både metadata om transaksjonen i `commitInfo`, og informasjon om nye data-filer i  `add`-delen. Vi ser at det er en veldig rik beskrivelse av endringer, men det kan være vanskeig å lese innholdet direkte. La oss heller bruke `history()`-funksjonen som kommer med `delta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff024b-ebee-409e-943f-7625b7d78a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = deltaTable.history()\n",
    "history.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f816dfa-4c37-40f5-b5dd-ca70613de8c0",
   "metadata": {},
   "source": [
    "Siden det blit trangt i tabellen over så kan vi velge hvilke variabler vi ønsker å se på:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596ee4f-5773-4f24-a1fb-621574f4e1ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Oversikt over alle kolonner som finnes i historien\n",
    "history.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa4548-8ab3-406b-a76e-ea9b4191bf71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Velger de kolonnene jeg er interessert i\n",
    "selected_history = deltaTable.history().select(\n",
    "    \"version\", \"timestamp\", \"operation\", \"operationParameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178957e-f735-4434-8b1b-d94a9d77ee93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the selected columns\n",
    "selected_history.show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48fced-793b-4c27-b8c5-321f9f7372d0",
   "metadata": {},
   "source": [
    "## Egendefinert metadata\n",
    "\n",
    "Delta Lake støtter også egendefinert metadata. Det kan for eksempel være nyttig hvis man ønsker å bruke Delta Lake som en backend for et GUI som lar brukeren oppdatere en tabell fra GUI-et. Da ønsker man typisk å lagre hvem som gjorde endringer og når det ble gjort. La oss legge på noe slik metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80128e45-f7a3-4050-b34e-539b814e4f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leser inn filen\n",
    "df = spark.read.format(\"delta\").load(\"gs://ssb-dapla-felles-data-delt-prod/temp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec5ce9-87d2-41c0-ac51-5cf425b95be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| label: show-meta\n",
    "#| code-fold: true\n",
    "\n",
    "# Lagrer egendefinert metadata i en json-fil\n",
    "import json\n",
    "\n",
    "metadata = {\n",
    "    \"comment\": \"Kontaktet oppgavegiver og kranglet!\",\n",
    "    \"manueltEditert\": \"True\",\n",
    "    \"maskineltEditert\": \"False\",\n",
    "}\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c8b51-0a29-48ed-8c99-de279d2a7949",
   "metadata": {},
   "source": [
    "Vi kan deretter appende dette til den siste versjonen av fila. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ae1c3-64b8-4864-b174-443481aa5364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df.write.format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .option(\"userMetadata\", json.dumps(metadata))  # Serialize metadata to a string\n",
    "    .save(\"gs://ssb-dapla-felles-data-delt-prod/temp4\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e15b79-7bd1-44ec-a278-e5f758122ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Laster inn tabellen\n",
    "deltaTable = DeltaTable.forPath(spark, \"gs://ssb-dapla-felles-data-delt-prod/temp4\")\n",
    "\n",
    "# Henter ut historien\n",
    "history_df = deltaTable.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da236532-cacb-4e23-8669-f323944a2326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the operation details, including metadata\n",
    "history_df.select(\n",
    "    \"version\", \"timestamp\", \"operation\", \"operationParameters\", \"userMetadata\"\n",
    ").show(truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004531b-c729-4f63-9495-1bd45adce7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_df.select(\"version\", \"userMetadata\").show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1db1b5-cfd9-41fb-a86a-8ef5968aa04f",
   "metadata": {},
   "source": [
    "Vi ser at vi la til vår egen metadata i versjon 3 av fila. Vi kan printe ut den rå transaksjonsloggen som tidligere, men nå er vi på transaksjon 3 `00000000000000000003.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5099b8b-408b-420d-828d-6689c746160f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dapla import FileClient\n",
    "\n",
    "# Kobler oss på bøttene\n",
    "fs = FileClient.get_gcs_file_system()\n",
    "\n",
    "# Filsti\n",
    "path = \"gs://ssb-dapla-felles-data-delt-prod/temp4/_delta_log/00000000000000000003.json\"\n",
    "\n",
    "with fs.open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        pretty_content = json.dumps(data, indent=4)\n",
    "        print(pretty_content)\n",
    "        print(\"-\" * 50)  # Print separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cbbd4a-ea13-425e-a65e-0e2f4acc777d",
   "metadata": {},
   "source": [
    "Vi er da at metadataene ligger som forventet i metadata-delen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delta-lake-manual",
   "language": "python",
   "name": "delta-lake-manual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
